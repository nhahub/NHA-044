{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import mediapipe as mp\n",
        "import joblib\n",
        "import zipfile\n",
        "import tempfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "6RDG1N23gUHm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_hands = mp.solutions.hands\n",
        "train_folder_path = r'/train.zip'\n",
        "val_folder_path = r'/val_final.zip'\n",
        "test_folder_path = r'/test_final.zip'"
      ],
      "metadata": {
        "id": "IpY93DUCgaXZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_zip(zip_path, extract_to):\n",
        "    \"\"\"\n",
        "    Extract zip file to temporary directory\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return extract_to"
      ],
      "metadata": {
        "id": "xrbAfpN_o_0t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hand_landmarks(image_path, hands):\n",
        "    \"\"\"\n",
        "    Extract hand landmarks from image using MediaPipe\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            return None\n",
        "\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = hands.process(image_rgb)\n",
        "\n",
        "        if results.multi_hand_landmarks:\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "\n",
        "            # Extract all 21 landmarks (x, y, z coordinates)\n",
        "            landmarks = []\n",
        "            for landmark in hand_landmarks.landmark:\n",
        "                landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "\n",
        "            return np.array(landmarks)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ocVwXZGhggj8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(point1, point2):\n",
        "    \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
        "    return np.sqrt((point1.x - point2.x)**2 +\n",
        "                  (point1.y - point2.y)**2 +\n",
        "                  (point1.z - point2.z)**2)"
      ],
      "metadata": {
        "id": "T8nEyKyagj20"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_enhanced_features(hand_landmarks):\n",
        "    \"\"\"\n",
        "    Extract additional geometric features\n",
        "    \"\"\"\n",
        "    enhanced_features = []\n",
        "\n",
        "    # Convert list back to landmark points for calculations\n",
        "    landmarks = []\n",
        "    for i in range(0, len(hand_landmarks), 3):\n",
        "        class Point:\n",
        "            def __init__(self, x, y, z):\n",
        "                self.x, self.y, self.z = x, y, z\n",
        "        landmarks.append(Point(hand_landmarks[i], hand_landmarks[i+1], hand_landmarks[i+2]))\n",
        "\n",
        "    # Finger lengths (thumb, index, middle, ring, pinky)\n",
        "    finger_tips = [4, 8, 12, 16, 20]\n",
        "    finger_mcps = [2, 5, 9, 13, 17]\n",
        "\n",
        "    for tip, mcp in zip(finger_tips, finger_mcps):\n",
        "        length = calculate_distance(landmarks[tip], landmarks[mcp])\n",
        "        enhanced_features.append(length)\n",
        "\n",
        "    # Palm size (distance between wrist and middle finger MCP)\n",
        "    palm_size = calculate_distance(landmarks[0], landmarks[9])\n",
        "    enhanced_features.append(palm_size)\n",
        "\n",
        "    return enhanced_features"
      ],
      "metadata": {
        "id": "LcWqhk6NgnIo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_enhanced_dataset_from_zip(zip_path):\n",
        "    \"\"\"\n",
        "    Create dataset with enhanced features from zip file\n",
        "    \"\"\"\n",
        "    # Create temporary directory for extraction\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    print(f\"Extracting {zip_path} to {temp_dir}\")\n",
        "\n",
        "    try:\n",
        "        # Extract zip file\n",
        "        extract_zip(zip_path, temp_dir)\n",
        "\n",
        "        hands = mp_hands.Hands(\n",
        "            static_image_mode=True,\n",
        "            max_num_hands=1,\n",
        "            min_detection_confidence=0.5\n",
        "        )\n",
        "\n",
        "        landmarks_list = []\n",
        "        labels_list = []\n",
        "\n",
        "        # Walk through extracted directory\n",
        "        for root, dirs, files in os.walk(temp_dir):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    full_path = os.path.join(root, file)\n",
        "\n",
        "                    # Get class label from parent directory name\n",
        "                    parent_folder = os.path.basename(root)\n",
        "\n",
        "                    # Skip if we're in the root temp directory without class folders\n",
        "                    if parent_folder == os.path.basename(temp_dir):\n",
        "                        # Look for actual class folders\n",
        "                        for item in os.listdir(temp_dir):\n",
        "                            item_path = os.path.join(temp_dir, item)\n",
        "                            if os.path.isdir(item_path) and item != os.path.basename(temp_dir):\n",
        "                                parent_folder = item\n",
        "                                break\n",
        "\n",
        "                    # Extract basic landmarks\n",
        "                    basic_landmarks = extract_hand_landmarks(full_path, hands)\n",
        "\n",
        "                    if basic_landmarks is not None:\n",
        "                        # Extract enhanced features\n",
        "                        enhanced_features = extract_enhanced_features(basic_landmarks)\n",
        "\n",
        "                        # Combine basic landmarks and enhanced features\n",
        "                        all_features = np.concatenate([basic_landmarks, enhanced_features])\n",
        "\n",
        "                        landmarks_list.append(all_features)\n",
        "                        labels_list.append(parent_folder)\n",
        "\n",
        "        hands.close()\n",
        "        return np.array(landmarks_list), np.array(labels_list)\n",
        "\n",
        "    finally:\n",
        "        # Clean up temporary directory\n",
        "        shutil.rmtree(temp_dir)"
      ],
      "metadata": {
        "id": "XXX4ME3egs54"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN EXECUTION\n",
        "print(\"=\"*50)\n",
        "print(\"EXTRACTING HAND LANDMARKS FROM ZIP FILES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check if zip files exist\n",
        "for zip_path in [train_folder_path, val_folder_path, test_folder_path]:\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Warning: {zip_path} not found!\")\n",
        "    else:\n",
        "        print(f\"Found: {zip_path}\")\n",
        "\n",
        "# Extract features from zip files\n",
        "print(\"\\nProcessing training set...\")\n",
        "X_train, y_train = create_enhanced_dataset_from_zip(train_folder_path)\n",
        "\n",
        "print(\"\\nProcessing validation set...\")\n",
        "X_val, y_val = create_enhanced_dataset_from_zip(val_folder_path)\n",
        "\n",
        "print(\"\\nProcessing test set...\")\n",
        "X_test, y_test = create_enhanced_dataset_from_zip(test_folder_path)\n",
        "\n",
        "# Check if we have enough data\n",
        "if len(X_train) == 0:\n",
        "    raise ValueError(\"No hand landmarks were extracted from training data!\")\n",
        "\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Training: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"Test: {X_test.shape[0]} samples\")\n",
        "if len(X_train) > 0:\n",
        "    print(f\"Number of features per sample: {X_train.shape[1]}\")\n",
        "\n",
        "# Get class information\n",
        "class_names = sorted(np.unique(y_train))\n",
        "num_classes = len(class_names)\n",
        "label_to_idx = {label: idx for idx, label in enumerate(class_names)}\n",
        "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
        "\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Classes: {class_names}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PREPROCESSING DATA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Encode labels to integers\n",
        "y_train_encoded = np.array([label_to_idx[label] for label in y_train])\n",
        "y_val_encoded = np.array([label_to_idx[label] for label in y_val])\n",
        "y_test_encoded = np.array([label_to_idx[label] for label in y_test])\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data preprocessing completed!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BASIC SVM TRAINING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Train basic SVM classifier\n",
        "svm_classifier = SVC(\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    gamma='scale',\n",
        "    probability=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training SVM...\")\n",
        "svm_classifier.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred = svm_classifier.predict(X_val_scaled)\n",
        "val_accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_test_pred = svm_classifier.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Save the basic model\n",
        "basic_model_data = {\n",
        "    'svm_model': svm_classifier,\n",
        "    'scaler': scaler,\n",
        "    'label_to_idx': label_to_idx,\n",
        "    'idx_to_label': idx_to_label,\n",
        "    'class_names': class_names\n",
        "}\n",
        "\n",
        "joblib.dump(basic_model_data, 'basic_enhanced_model.pkl')\n",
        "print(\"\\nBasic enhanced model saved as 'basic_enhanced_model.pkl'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BASIC MODEL TRAINING COMPLETED!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "if len(X_train) > 0:\n",
        "    print(f\"Number of features: {X_train.shape[1]}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_test_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7lz2NHAgwzh",
        "outputId": "f08d79b4-a4d3-48ba-91e6-49fe2c248a85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "EXTRACTING HAND LANDMARKS FROM ZIP FILES\n",
            "==================================================\n",
            "Found: /train.zip\n",
            "Found: /val_final.zip\n",
            "Found: /test_final.zip\n",
            "\n",
            "Processing training set...\n",
            "Extracting /train.zip to /tmp/tmppblel3_q\n",
            "\n",
            "Processing validation set...\n",
            "Extracting /val_final.zip to /tmp/tmpkt0rnwuf\n",
            "\n",
            "Processing test set...\n",
            "Extracting /test_final.zip to /tmp/tmpg77ct7ta\n",
            "\n",
            "Dataset sizes:\n",
            "Training: 13606 samples\n",
            "Validation: 2051 samples\n",
            "Test: 2059 samples\n",
            "Number of features per sample: 69\n",
            "Number of classes: 32\n",
            "Classes: ['ain', 'al', 'aleff', 'bb', 'dal', 'dha', 'dhad', 'fa', 'gaaf', 'ghain', 'ha', 'haa', 'jeem', 'kaaf', 'khaa', 'la', 'laam', 'meem', 'nun', 'ra', 'saad', 'seen', 'sheen', 'ta', 'taa', 'thaa', 'thal', 'toot', 'waw', 'ya', 'yaa', 'zay']\n",
            "\n",
            "==================================================\n",
            "PREPROCESSING DATA\n",
            "==================================================\n",
            "Data preprocessing completed!\n",
            "\n",
            "==================================================\n",
            "BASIC SVM TRAINING\n",
            "==================================================\n",
            "Training SVM...\n",
            "Validation Accuracy: 0.9200\n",
            "Test Accuracy: 0.9024\n",
            "\n",
            "Basic enhanced model saved as 'basic_enhanced_model.pkl'\n",
            "\n",
            "==================================================\n",
            "BASIC MODEL TRAINING COMPLETED!\n",
            "==================================================\n",
            "Final Test Accuracy: 0.9024\n",
            "Number of features: 69\n",
            "Number of classes: 32\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ain       0.95      0.94      0.94        62\n",
            "          al       0.98      0.83      0.90        65\n",
            "       aleff       1.00      0.99      0.99        67\n",
            "          bb       0.89      0.94      0.91        66\n",
            "         dal       0.90      0.82      0.86        56\n",
            "         dha       0.90      0.99      0.94        67\n",
            "        dhad       0.94      0.94      0.94        65\n",
            "          fa       0.87      0.79      0.83        67\n",
            "        gaaf       0.85      0.89      0.87        62\n",
            "       ghain       0.94      1.00      0.97        67\n",
            "          ha       0.92      0.90      0.91        62\n",
            "         haa       0.85      0.91      0.88        57\n",
            "        jeem       0.95      0.97      0.96        63\n",
            "        kaaf       0.85      0.67      0.75        67\n",
            "        khaa       0.97      0.88      0.92        64\n",
            "          la       1.00      0.97      0.98        65\n",
            "        laam       0.96      0.83      0.89        65\n",
            "        meem       0.90      0.88      0.89        65\n",
            "         nun       0.92      0.89      0.90        61\n",
            "          ra       0.81      0.90      0.85        61\n",
            "        saad       0.86      0.95      0.91        66\n",
            "        seen       0.66      0.91      0.77        68\n",
            "       sheen       0.97      0.84      0.90        67\n",
            "          ta       0.83      0.95      0.89        65\n",
            "         taa       0.90      0.91      0.91        68\n",
            "        thaa       1.00      0.91      0.95        67\n",
            "        thal       0.90      0.85      0.87        65\n",
            "        toot       0.89      0.86      0.87        63\n",
            "         waw       0.94      0.97      0.95        60\n",
            "          ya       0.96      1.00      0.98        66\n",
            "         yaa       0.90      0.91      0.90        67\n",
            "         zay       0.89      0.90      0.90        63\n",
            "\n",
            "    accuracy                           0.90      2059\n",
            "   macro avg       0.91      0.90      0.90      2059\n",
            "weighted avg       0.91      0.90      0.90      2059\n",
            "\n"
          ]
        }
      ]
    }
  ]
}